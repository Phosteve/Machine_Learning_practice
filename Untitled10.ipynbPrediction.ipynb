{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled10.ipynbPrediction.ipynb","provenance":[],"authorship_tag":"ABX9TyP4ge9CnEzU9IssWRYXYgKT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":[""],"metadata":{"id":"NgDz8klZEigK"}},{"cell_type":"markdown","source":["importing the dependencies"],"metadata":{"id":"wVKUVYQxEluu"}},{"cell_type":"code","execution_count":5,"metadata":{"id":"gRloGxUPEL76","executionInfo":{"status":"ok","timestamp":1651849137728,"user_tz":-180,"elapsed":1629,"user":{"displayName":"Phosteve Sachieng","userId":"17290058021993400429"}}},"outputs":[],"source":["%tensorflow_version 2.x"]},{"cell_type":"code","source":["#@title Load the imports\n","# from__future__import absolute_import, division, print_function, unicode_literals\n","import numpy as np\n","import pandas  as pd\n","import tensorflow as tf\n","from tensorflow import feature_column\n","from tensorflow.keras import layers\n","\n","from matplotlib import pyplot as pyplot\n","\n","# The following lines adjust the granularity of reporting.\n","pd.options.display.max_rows = 10\n","pd.options.display.float_format = \"{:.1f}\".format\n","\n","tf.keras.backend.set_floatx('float32')\n","\n","print(\"Imported the modules.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sTIOU4oEF8BO","executionInfo":{"status":"ok","timestamp":1651849138461,"user_tz":-180,"elapsed":9,"user":{"displayName":"Phosteve Sachieng","userId":"17290058021993400429"}},"outputId":"8b5a0668-3eef-476a-9244-939a3b9c68fb"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Imported the modules.\n"]}]},{"cell_type":"code","source":["# Load the dataset\n","train_df = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_train.csv\")\n","test_df = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_test.csv\")\n","\n","#Scale the labels\n","scale_factor = 1000.0\n","#Scale the training set's label.\n","train_df[\"median_house_value\"] /= scale_factor\n","#Scale the test set's label.\n","test_df[\"median_house_value\"] /= scale_factor\n","# Shuffle the examples\n","train_df = train_df.reindex(np.random.permutation(train_df.index))"],"metadata":{"id":"iVZh4x9glhHN","executionInfo":{"status":"ok","timestamp":1651849140903,"user_tz":-180,"elapsed":7,"user":{"displayName":"Phosteve Sachieng","userId":"17290058021993400429"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Create an empty list that will eventually hold all feature columns.\n","feature_columns = []\n","#Create a numerical feature  column to represet latitude.\n","latitude = tf.feature_column.numeric_column(\"latitude\")\n","feature_columns.append(latitude)\n","\n","# Create a numerical feature column to represent longitude.\n","longitude = tf.feature_column.sequence_numeric_column(\"longitude\")\n","feature_columns.append(longitude)\n","\n","#Convert the list of feature columns into layer that will ultimately become\n","# part of the model. Understanding layers is not important right now.\n","fp_feature_layer = layers.DenseFeatures(feature_columns)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":467},"id":"rtT9OxR6o-Gs","executionInfo":{"status":"error","timestamp":1651849151187,"user_tz":-180,"elapsed":549,"user":{"displayName":"Phosteve Sachieng","userId":"17290058021993400429"}},"outputId":"fe11a6e4-3b8e-48bc-e1a2-20ba3826f79a"},"execution_count":8,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-eab117ea9ef5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#Convert the list of feature columns into layer that will ultimately become\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# part of the model. Understanding layers is not important right now.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mfp_feature_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDenseFeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/feature_column/dense_features_v2.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, feature_columns, trainable, name, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         **kwargs)\n\u001b[0m\u001b[1;32m     88\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_StateManagerImplV2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/feature_column/dense_features.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, feature_columns, trainable, name, partitioner, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mexpected_column_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDenseColumn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         **kwargs)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/feature_column/base_feature_layer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, feature_columns, expected_column_type, trainable, name, partitioner, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;34m'You can wrap a categorical column with an '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             'embedding_column or indicator_column. Given: {}'.format(\n\u001b[0;32m---> 71\u001b[0;31m                 expected_column_type, column))\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Items of feature_columns must be a <class 'tensorflow.python.feature_column.feature_column_v2.DenseColumn'>. You can wrap a categorical column with an embedding_column or indicator_column. Given: SequenceNumericColumn(key='longitude', shape=(1,), default_value=0.0, dtype=tf.float32, normalizer_fn=None)"]}]},{"cell_type":"code","source":["#@title Define functions to create and train a model, and a plotting function\n","def create_model(my_learning_rate, feature_layer):\n","  \"\"\"Create and compile a simple regression model.\"\"\"\n","  # Most simple tf.keras models are sequential.\n","  model = tf.keras.models.Sequential()\n","\n","  #Add the layer containing the feature columns to  the model.\n","  model.add(feature_layer)\n","\n","  # Add one linear layer to the model to yield a simple linear regression\n","  model.add(tf.keras.layers.Dense(units=1, input_shape=(1,)))\n","\n","  # Construct the layers into a model that TensorFlow can execute.\n","  model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=my_learning_rate),\n","                loss=\"mean_squared_error\",\n","                metrics=[tf.keras.metrics.RootMeanSquaredError()])\n","  \n","  return model\n","\n","def train_model(model, dataset, epochs, batch_size, label_name):\n","  \"\"\"Feed a dataset into the model in order to train  it.\"\"\"\n","  features = {name:np.array(value) for name, value in dataset.items()}\n","  label = np.array(features.pop(label_name))\n","  hhistory = model.fit(x=features, y=label, batch_size=batch_size,\n","                       epochs=epochs, shuffle=True)\n","  epochs = history.epoch\n","  hist = pd.DataFrame(history.history)\n","  rmse = hist[\"root_mean_squared_error\"]\n","\n","  return epochs, rmse\n","\n","def plot_the_loss_curve(epochs, rmse):\n","  \"\"\"Plot a curve of loss vs. epoch.\"\"\"\n","\n","  plt.figure()\n","  plt.xlabel(\"Epoch\")\n","  plt.ylabel(\"Root Mean Squared Error\")\n","\n","  plt.plot(epochs, rmse, label=\"Loss\")\n","  plt.legend()\n","  plt.ylim([rmse.min()*0.94, rmse.max()*1.05])\n","  plt.show()\n","\n","print(\"Defined the create_model, train_model, and plot_the_loss_curve functions. \")\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oNxwbVe8wyQb","executionInfo":{"status":"ok","timestamp":1651852379737,"user_tz":-180,"elapsed":525,"user":{"displayName":"Phosteve Sachieng","userId":"17290058021993400429"}},"outputId":"7701727f-1223-4187-d52d-0fad88ff8eef"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Defined the create_model, train_model, and plot_the_loss_curve functions. \n"]}]},{"cell_type":"code","source":["learning_rate = 0.05\n","epochs = 30\n","batch_size = 100\n","label_name = 'median_house_value'\n","my_model = create_model(learning_rate, fp_feature_layer)\n","epochs, rmse = train_model(my_model, train_df, epochs, batch_size, label_name)\n","plot_the_loss_curve(epochs, rmse)\n","print(\"\\n: Evaluate the new model against the test set:\")\n","test_features = {name:np.array(value) for name, value in test_df.items()}\n","test_label = np.array(test_features.pop(label_name))\n","my_model.evaluate(x=test_features, y=test_label, batch_size=batch_size)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":252},"id":"Zu9gmOndEwAW","executionInfo":{"status":"error","timestamp":1651853122026,"user_tz":-180,"elapsed":521,"user":{"displayName":"Phosteve Sachieng","userId":"17290058021993400429"}},"outputId":"30a2cc64-0b21-4ba2-e6d5-e26cfa81a3ae"},"execution_count":10,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-e5a5dd4013a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlabel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'median_house_value'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmy_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp_feature_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplot_the_loss_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'fp_feature_layer' is not defined"]}]},{"cell_type":"code","source":["resolution_in_degrees = 1.0\n","feature_columns = []\n","latitude_as_a_numeric_column = tf.feature_column.numeric_column(\"latitude\")\n","latitude_boundaries = list(np.arange(int(min(train_df['latitude'])),\n","                                     int(max(train_df['latitude']),\n","                                         resolution_in_degrees)))\n","latitude = tf.feature_column.bucketized_column(latitude_as_a_numeric_column,\n","                                               latitude_boundaries)\n","feature_columns.append(latitude)\n","longitude_as_a_numeric_column = tf.feature_column.numeric_column(\"longitude\")\n","longitude_boundaries = list(np.arange(int(min(train_df['longitude'])),\n","                                      int(max(train_df['longitude'])),\n","                                      resolution_in_degrees))\n","longitude = tf.feature_column.bucketized_column(longitude_as_a_numeric_column,\n","                                                longitude_boundaries)\n","feature_columns.append(longitude)\n","buckets_feature_layer = layers.DenseFeatures(feature_columns)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":252},"id":"UBJMXHLiHlIp","executionInfo":{"status":"error","timestamp":1651854371529,"user_tz":-180,"elapsed":508,"user":{"displayName":"Phosteve Sachieng","userId":"17290058021993400429"}},"outputId":"b9aa97ff-7be9-48d6-b5ec-447ddca3f59d"},"execution_count":11,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-316ce858b178>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m latitude_boundaries = list(np.arange(int(min(train_df['latitude'])),\n\u001b[1;32m      5\u001b[0m                                      int(max(train_df['latitude']),\n\u001b[0;32m----> 6\u001b[0;31m                                          resolution_in_degrees)))\n\u001b[0m\u001b[1;32m      7\u001b[0m latitude = tf.feature_column.bucketized_column(latitude_as_a_numeric_column,\n\u001b[1;32m      8\u001b[0m                                                latitude_boundaries)\n","\u001b[0;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an integer"]}]},{"cell_type":"code","source":["learning_rate = 0.04\n","epochs = 35\n","\n","my_model = create_model(learning_rate, buckets_feature_layer)\n","epochs, rmse = train_model(my_model, train_df, epochs,batch_size, label_name)\n","plot_the_loss_curve(epochs rmse)\n","print(\"\\n: Evaluate the new model against the test set:\")\n","my_model.evaluate(x=test_features, y=test_label, batch_size=batch_size)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":130},"id":"35noc-FyMWJb","executionInfo":{"status":"error","timestamp":1651855022057,"user_tz":-180,"elapsed":629,"user":{"displayName":"Phosteve Sachieng","userId":"17290058021993400429"}},"outputId":"d57ca67d-8827-4e10-c9d3-a179626c9d19"},"execution_count":12,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-4f1fb485b886>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    plot_the_loss_curve(epochs rmse)\u001b[0m\n\u001b[0m                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"cell_type":"code","source":["resolution_in_degrees = 1.0\n","feature_columns = []\n","latitude_as_a_numeric_column = tf.feature_column.numeric_column(\"latitude\")\n","latitude_boundaries = list(np.arange(int(min(train_df['latitude'])), int(max(train_df['latitude'])), resolution_in_degrees))\n","latitude = tf.feature_column.bucketized_column(latitude_as_a_numeric_column, longitude_boundaries)\n","longitude_as_a_numeric_column = tf.feature_column.numeric_column(\"longitude\")\n","longitude_boundaries = list(np.arange(int(min(train_df['longitude'])), int(max(train_df['longitude'])), resolution_in_degrees))\n","longiitude = tf.feature_column.bucketized_column(longitude_as_a_numeric_column, longitude_boundaries)\n","latitude_x_longitude = tf.feature_"],"metadata":{"id":"zP1ZpxaGO1BG"},"execution_count":null,"outputs":[]}]}